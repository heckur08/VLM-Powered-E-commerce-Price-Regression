# -*- coding: utf-8 -*-
"""amazon_ml_challenge.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10tZ0epHwXt1m-3y9oCbvAEk46EOheykD
"""

import os
os.environ['TORCHDYNAMO_DISABLE'] = '1'

from unsloth import FastVisionModel

import torch
import torch.nn as nn
import pandas as pd
import numpy as np
from PIL import Image
from sklearn.model_selection import train_test_split
from torch.utils.data import Dataset
from transformers import (
    PreTrainedModel,
    PretrainedConfig,
    Trainer,
    TrainingArguments,
)
import warnings
warnings.filterwarnings('ignore')

# Check for GPU availability before doing anything else
if not torch.cuda.is_available():
    raise SystemExit(
        "CUDA is not available. Please ensure you are running on a GPU node and that your PyTorch installation has CUDA support."
    )

print(f"GPUs available: {torch.cuda.device_count()}")
for i in range(torch.cuda.device_count()):
    print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")

# ===================================================================================
# 1. CONFIGURATION
# ===================================================================================
class Config:
    """Holds all static parameters for the training run."""

    # --- Data Paths ---
    TRAIN_CSV_PATH = "/home/subhamr__iitp/amlc/train.csv"
    IMAGE_DIR = "/home/subhamr__iitp/amlc/dataset/images/train"

    # --- Model & Tokenizer ---
    MODEL_NAME = "/home/subhamr__iitp/amlc/hf_cache_llava/models--llava-hf--llava-1.5-7b-hf/snapshots/b234b804b114d9e37bb655e11cbbb5f5e971b7a9"
    MAX_SEQ_LENGTH = 768

    # --- Training & Validation ---
    NUM_ROWS = 200  # Set to None to use the full dataset, or an integer for a subset.
    VALIDATION_SPLIT_SIZE = 0.1
    RANDOM_SEED = 42

    # --- Price Preprocessing ---
    USE_LOG_TRANSFORM = True  # Highly recommended for price prediction

    # --- Hyperparameters (Optimized for A100) ---
    EPOCHS = 10
    BATCH_SIZE = 32  # Much larger batch size for A100 80GB without quantization
    GRAD_ACCUMULATION_STEPS = 1  # No accumulation needed with large batch
    LEARNING_RATE = 5e-5  # Lower LR for stability
    WEIGHT_DECAY = 0.01
    WARMUP_RATIO = 0.1  # Gradual warmup for stable training

    # --- Output ---
    OUTPUT_DIR = "./llava_price_regressor_output"
    LOGGING_STEPS = 10

    # --- Compute (Optimized) ---
    DEVICE = "cuda"
    DTYPE = torch.bfloat16
    USE_QUANTIZATION = False  # No quantization for maximum speed

    # --- DataLoader Optimization ---
    DATALOADER_NUM_WORKERS = 8  # Parallel data loading
    DATALOADER_PIN_MEMORY = True
    DATALOADER_PREFETCH_FACTOR = 2

    # --- Early Stopping ---
    EARLY_STOPPING_PATIENCE = 3

# ===================================================================================
# 2. EVALUATION METRIC (SMAPE)
# ===================================================================================
def smape(y_true, y_pred):
    """Calculates Symmetric Mean Absolute Percentage Error."""
    y_true, y_pred = np.array(y_true), np.array(y_pred)
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    ratio = np.where(denominator == 0, 0, numerator / denominator)
    return np.mean(ratio) * 100

# ===================================================================================
# 3. DATASET CLASS (Optimized)
# ===================================================================================
class PricePredictionDataset(Dataset):
    """PyTorch Dataset for loading product images, prompts, and prices."""
    def __init__(self, dataframe, image_dir, image_token, use_log_transform=False):
        self.df = dataframe.reset_index(drop=True)
        self.image_dir = image_dir
        self.image_token = image_token
        self.use_log_transform = use_log_transform

        # Pre-check which images exist to avoid repeated file checks
        self.valid_images = {}
        print("Pre-checking image availability...")
        for idx in range(len(self.df)):
            sample_id = self.df.iloc[idx]['sample_id']
            img_path = os.path.join(self.image_dir, f"{sample_id}.jpg")
            self.valid_images[idx] = os.path.exists(img_path)

        missing_count = sum(1 for v in self.valid_images.values() if not v)
        print(f"Found {len(self.df) - missing_count}/{len(self.df)} valid images")

    def __len__(self):
        return len(self.df)

    def _build_prompt(self, content: str) -> str:
        sanitized_content = str(content).replace(self.image_token, "")
        return f"USER: {self.image_token}\nAnalyze this product and predict its price: {sanitized_content}\nASSISTANT:"

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        sample_id = row['sample_id']
        img_path = os.path.join(self.image_dir, f"{sample_id}.jpg")

        # Use pre-checked image validity
        if self.valid_images[idx]:
            try:
                image = Image.open(img_path).convert("RGB")
            except Exception as e:
                image = Image.new('RGB', (224, 224), color='white')
        else:
            image = Image.new('RGB', (224, 224), color='white')

        prompt = self._build_prompt(row['catalog_content'])
        price = row['price']

        # Apply log transform if enabled
        if self.use_log_transform:
            price = np.log1p(price)

        price = torch.tensor(price, dtype=torch.float32)

        return {
            "image": image,
            "prompt": prompt,
            "labels": price,
        }

# ===================================================================================
# 4. CUSTOM MODEL ARCHITECTURE
# ===================================================================================
class LLaVARegressionConfig(PretrainedConfig):
    """Custom config class to enable saving/loading our composite model."""
    model_type = "llava_regression"
    def __init__(self, llava_model_name="", use_log_transform=False, **kwargs):
        super().__init__(**kwargs)
        self.llava_model_name = llava_model_name
        self.use_log_transform = use_log_transform

class LLaVARegressionModel(PreTrainedModel):
    """
    A custom model that wraps a frozen LLaVA base with a trainable regression head.
    Optimized for multi-GPU training without quantization.
    """
    config_class = LLaVARegressionConfig

    def __init__(self, config):
        super().__init__(config)

        # Load the base LLaVA model without quantization for maximum speed
        if Config.USE_QUANTIZATION:
            self.llava, self.processor = FastVisionModel.from_pretrained(
                model_name=config.llava_model_name,
                max_seq_length=Config.MAX_SEQ_LENGTH,
                dtype=Config.DTYPE,
                load_in_4bit=True,
            )
        else:
            # No quantization - full precision for speed
            self.llava, self.processor = FastVisionModel.from_pretrained(
                model_name=config.llava_model_name,
                max_seq_length=Config.MAX_SEQ_LENGTH,
                dtype=Config.DTYPE,
                load_in_4bit=False,
            )

        # Freeze all parameters of the base LLaVA model
        for param in self.llava.parameters():
            param.requires_grad = False

        # Move base model to eval mode for efficiency
        self.llava.eval()

        # Define the trainable regression head (optimized architecture)
        llava_hidden_size = self.llava.config.text_config.hidden_size
        self.reg_head = nn.Sequential(
            nn.Linear(llava_hidden_size, 1024),
            nn.LayerNorm(1024),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.LayerNorm(512),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(512, 256),
            nn.LayerNorm(256),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(256, 1)
        )

        self.use_log_transform = config.use_log_transform

    def forward(self, input_ids, pixel_values, attention_mask, labels=None, **kwargs):
        # Get outputs from the frozen LLaVA base model
        with torch.no_grad():
            llava_outputs = self.llava(
                input_ids=input_ids,
                attention_mask=attention_mask,
                pixel_values=pixel_values,
                output_hidden_states=True
            )

        # Use the last hidden state
        last_hidden_state = llava_outputs.hidden_states[-1]

        # Perform masked mean pooling
        masked_hidden_state = last_hidden_state * attention_mask.unsqueeze(-1)
        sum_hidden_state = torch.sum(masked_hidden_state, dim=1)
        sum_attention_mask = torch.sum(attention_mask, dim=1).unsqueeze(-1)
        pooled_embedding = sum_hidden_state / sum_attention_mask.clamp(min=1e-9)

        # Pass through regression head
        predicted_price = self.reg_head(pooled_embedding).squeeze(-1)

        loss = None
        if labels is not None:
            loss_fct = nn.MSELoss()
            loss = loss_fct(predicted_price.float(), labels.float())

        return {"loss": loss, "logits": predicted_price}

# ===================================================================================
# 5. CUSTOM CALLBACKS
# ===================================================================================
from transformers import TrainerCallback, EarlyStoppingCallback

class PerformanceMonitorCallback(TrainerCallback):
    """Monitor and log training performance metrics."""
    def __init__(self):
        self.start_time = None
        self.step_times = []

    def on_train_begin(self, args, state, control, **kwargs):
        import time
        self.start_time = time.time()
        print(f"\n{'='*60}")
        print(f"Starting training with optimized configuration")
        print(f"Batch size: {args.per_device_train_batch_size}")
        print(f"Number of GPUs: {torch.cuda.device_count()}")
        print(f"Effective batch size: {args.per_device_train_batch_size * torch.cuda.device_count() * args.gradient_accumulation_steps}")
        print(f"{'='*60}\n")

    def on_step_end(self, args, state, control, **kwargs):
        if self.start_time and state.global_step % 50 == 0:
            import time
            elapsed = time.time() - self.start_time
            steps_per_sec = state.global_step / elapsed
            print(f"[Performance] Step {state.global_step}: {steps_per_sec:.2f} steps/sec")

# ===================================================================================
# 6. MAIN TRAINING SCRIPT
# ===================================================================================
def main():
    print("\n" + "="*80)
    print("LLaVA Price Prediction Fine-Tuning - OPTIMIZED FOR MULTI-GPU A100")
    print("="*80 + "\n")

    # --- Data Loading and Splitting ---
    print(f"Loading data from {Config.TRAIN_CSV_PATH}...")
    df = pd.read_csv(Config.TRAIN_CSV_PATH)

    if Config.NUM_ROWS is not None:
        print(f"⚠️  Using a subset of {Config.NUM_ROWS} rows for testing.")
        df = df.head(Config.NUM_ROWS)
    else:
        print(f"✓ Using FULL dataset: {len(df)} rows")

    # Data cleaning
    df.dropna(subset=['price', 'catalog_content'], inplace=True)
    df['price'] = pd.to_numeric(df['price'], errors='coerce')
    df.dropna(subset=['price'], inplace=True)

    # Price statistics (before transformation)
    print(f"\nPrice statistics (original):")
    print(f"  Min: ${df['price'].min():.2f}")
    print(f"  Max: ${df['price'].max():.2f}")
    print(f"  Mean: ${df['price'].mean():.2f}")
    print(f"  Median: ${df['price'].median():.2f}")

    if Config.USE_LOG_TRANSFORM:
        print(f"\n✓ Applying log transformation to prices")
        # Store original prices for reference
        df['original_price'] = df['price']
        df['price'] = np.log1p(df['price'])

    train_df, val_df = train_test_split(
        df, test_size=Config.VALIDATION_SPLIT_SIZE, random_state=Config.RANDOM_SEED
    )
    print(f"\n✓ Data split complete:")
    print(f"  Training samples: {len(train_df)}")
    print(f"  Validation samples: {len(val_df)}")

    # --- Model Initialization ---
    print(f"\nInitializing model: {Config.MODEL_NAME}")
    print(f"  Quantization: {'Enabled (4-bit)' if Config.USE_QUANTIZATION else 'Disabled (Full Precision)'}")
    print(f"  Data type: {Config.DTYPE}")

    model_config = LLaVARegressionConfig(
        llava_model_name=Config.MODEL_NAME,
        use_log_transform=Config.USE_LOG_TRANSFORM
    )
    model = LLaVARegressionModel(model_config)
    processor = model.processor

    # Count trainable parameters
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in model.parameters())
    print(f"\n✓ Model initialized:")
    print(f"  Total parameters: {total_params:,}")
    print(f"  Trainable parameters: {trainable_params:,} ({100 * trainable_params / total_params:.2f}%)")

    # --- Dataset and Collator Setup ---
    image_token = getattr(processor, "image_token", "<image>")
    train_dataset = PricePredictionDataset(
        train_df, Config.IMAGE_DIR, image_token, Config.USE_LOG_TRANSFORM
    )
    eval_dataset = PricePredictionDataset(
        val_df, Config.IMAGE_DIR, image_token, Config.USE_LOG_TRANSFORM
    )

    def custom_data_collator(batch):
        prompts = [item['prompt'] for item in batch]
        images = [item['image'] for item in batch]
        labels = torch.stack([item['labels'] for item in batch])

        inputs = processor(
            text=prompts,
            images=images,
            return_tensors='pt',
            padding=True,
            truncation=True,
            max_length=Config.MAX_SEQ_LENGTH
        )
        inputs['labels'] = labels
        return inputs

    def compute_metrics(eval_pred):
        logits, labels = eval_pred

        # Inverse transform if using log
        if Config.USE_LOG_TRANSFORM:
            logits_original = np.expm1(logits)
            labels_original = np.expm1(labels)
        else:
            logits_original = logits
            labels_original = labels

        smape_score = smape(labels_original, logits_original)
        mse = ((logits - labels) ** 2).mean()
        mae = np.abs(logits - labels).mean()

        # Original scale metrics
        mse_original = ((logits_original - labels_original) ** 2).mean()
        mae_original = np.abs(logits_original - labels_original).mean()

        return {
            'smape': smape_score,
            'mse': mse,
            'mae': mae,
            'mse_original_scale': mse_original,
            'mae_original_scale': mae_original,
        }

    # --- Trainer Configuration (OPTIMIZED) ---
    training_args = TrainingArguments(
        output_dir=Config.OUTPUT_DIR,
        per_device_train_batch_size=Config.BATCH_SIZE,
        per_device_eval_batch_size=Config.BATCH_SIZE,
        gradient_accumulation_steps=Config.GRAD_ACCUMULATION_STEPS,
        num_train_epochs=Config.EPOCHS,
        learning_rate=Config.LEARNING_RATE,
        weight_decay=Config.WEIGHT_DECAY,
        warmup_ratio=Config.WARMUP_RATIO,

        # Precision
        bf16=True,
        bf16_full_eval=True,

        # Optimization
        optim="adamw_torch_fused",  # Fused optimizer for speed
        max_grad_norm=1.0,

        # Logging
        logging_dir=f"{Config.OUTPUT_DIR}/logs",
        logging_steps=Config.LOGGING_STEPS,
        logging_first_step=True,

        # Evaluation and Saving
        eval_strategy="epoch",
        save_strategy="epoch",
        save_total_limit=3,
        load_best_model_at_end=True,
        metric_for_best_model="smape",
        greater_is_better=False,

        # DataLoader optimization
        dataloader_num_workers=Config.DATALOADER_NUM_WORKERS,
        dataloader_pin_memory=Config.DATALOADER_PIN_MEMORY,
        dataloader_prefetch_factor=Config.DATALOADER_PREFETCH_FACTOR,

        # Multi-GPU
        ddp_find_unused_parameters=False,

        # Misc
        remove_unused_columns=False,
        report_to=[],
        disable_tqdm=False,

        # Speed optimizations
        tf32=True,  # Use TF32 for matrix multiplications on Ampere GPUs
        torch_compile=False,  # Can be enabled but may need testing
    )

    # Initialize callbacks
    callbacks = [
        PerformanceMonitorCallback(),
        EarlyStoppingCallback(early_stopping_patience=Config.EARLY_STOPPING_PATIENCE)
    ]

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=eval_dataset,
        data_collator=custom_data_collator,
        compute_metrics=compute_metrics,
        callbacks=callbacks,
    )

    # --- Start Training ---
    print("\n" + "="*80)
    print("STARTING OPTIMIZED TRAINING")
    print("="*80 + "\n")

    import time
    train_start = time.time()

    trainer.train()

    train_time = time.time() - train_start
    print("\n" + "="*80)
    print(f"✓ Training finished in {train_time/60:.2f} minutes ({train_time:.1f} seconds)")
    print("="*80 + "\n")

    # --- Save the Final Model ---
    final_model_path = os.path.join(Config.OUTPUT_DIR, "best_regression_head.pth")
    print(f"Saving the trained regression head to {final_model_path}")
    torch.save({
        'model_state_dict': model.reg_head.state_dict(),
        'config': {
            'use_log_transform': Config.USE_LOG_TRANSFORM,
            'max_seq_length': Config.MAX_SEQ_LENGTH,
            'model_name': Config.MODEL_NAME,
        }
    }, final_model_path)

    # Save full model config
    model.config.save_pretrained(Config.OUTPUT_DIR)

    print("\n✓ Script finished successfully!")
    print(f"  Output directory: {Config.OUTPUT_DIR}")
    print(f"  Best model checkpoint: {trainer.state.best_model_checkpoint}")


if __name__ == "__main__":
    main()